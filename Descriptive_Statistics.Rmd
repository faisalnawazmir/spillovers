---
title: "Deskriptivní statistiky časových řad"
author: "Daniel Bartušek"
output: html_document
runtime: shiny
params:
  period:
    label: 'Data Period:'
    value: Full
    input: select
    choices:
    - All
    - Pre-GFC
    - GFC
    - EU debt crisis
    - Post-EU debt crisis
    - Covid
resource_files:
- data/shiny/break_dates/bp_break_dates_Diesel_log_ret.rds
- data/shiny/break_dates/bp_break_dates_Heating_Oil_log_ret.rds
- data/shiny/break_dates/bp_break_dates_Crude_Oil_WTI_log_ret.rds
- data/shiny/break_dates/bp_break_dates_Natural_Gas_log_ret.rds
- data/shiny/break_dates/bp_break_dates_NY_Gasoline_log_ret.rds
- data/shiny/plots/bp_plot_Crude_Oil_WTI_log_ret.rds
- data/shiny/plots/bp_plot_Diesel_log_ret.rds
- data/shiny/plots/bp_plot_Heating_Oil_log_ret.rds
- data/shiny/plots/bp_plot_Natural_Gas_log_ret.rds
- data/shiny/plots/bp_plot_NY_Gasoline_log_ret.rds
---
```{r include = F}
rm(list = ls())
options(scipen = 100, digits = 8)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(echo = TRUE)
quiet <- function(x) { 
  sink(tempfile()) 
  on.exit(sink()) 
  invisible(force(x)) 
}
```

```{r packages, echo = F }
library(ggplot2)
library(readxl)
library(ggpubr)
library(xts)
library(kableExtra)
library(stargazer)
library(tseries)
library(moments)
library(lmtest)
library(stringr)
library(frequencyConnectedness)
library(imputeTS)
library(ggcorrplot)
library(dplyr)
library(reshape2)
library(strucchange)
library(tidyverse)
```

## Load data

```{r load_data, include =F}
stylized_names <-c("Natural Gas","Crude Oil WTI","NY Gasoline","Heating Oil","Diesel")

holidays_df<-read_csv("data/shiny/US Holiday Dates (2004-2021).csv") %>% dplyr::select(1,2)

nat_gas_spot <- read_excel("data/shiny/NG_PRI_FUT_S1_D.xls", sheet = "Data 1", skip = 2) %>%
  rename("Natural_Gas" = 2)
crude_oil_spot <- read_excel("data/shiny/PET_PRI_SPT_S1_D.xls", sheet = "Data 1", skip = 2) %>%
  rename("Crude_Oil_WTI" = 2, "Crude_Oil_Europe_Brent" = 3)
gasoline <- read_excel("data/shiny/PET_PRI_SPT_S1_D.xls", sheet = "Data 2", skip = 2) %>%
  rename("NY_Gasoline" = 2, "Gulf_Gasoline" = 3)
heating_oil <- read_excel("data/shiny/PET_PRI_SPT_S1_D.xls", sheet = "Data 4", skip = 2) %>%
  rename("Heating_Oil" = 2)
diesel <- read_excel("data/shiny/PET_PRI_SPT_S1_D.xls", sheet = "Data 5", skip = 2) %>%
  dplyr::select(-2, -3) %>%
  rename("Diesel" = 2)

df <- nat_gas_spot %>%
  full_join(crude_oil_spot, by = "Date") %>%
  full_join(gasoline, by = "Date") %>%
  full_join(heating_oil, by = "Date") %>%
  full_join(diesel, by = "Date") %>%
  left_join(holidays_df,by="Date") %>%
  arrange(Date) %>%
  dplyr::filter(Date >= "1997-01-07") %>%
  mutate(Date=as.Date(Date),
         Day = weekdays(Date)) %>%
  dplyr::select(Date,Day,Holiday,Natural_Gas,Crude_Oil_WTI,NY_Gasoline,Heating_Oil,Diesel)
df_orig<-df
```




### Removing NAs

#### NA Overview
```{r NAs, echo = F}
print("Sum on NAs in each column")
colSums(is.na(df))
aux <- df[!complete.cases(df), ]
print("NA occurrences per weekday: no particular pattern in weekdays, although most reported on Monday")
table(aux$Day)
```


We see that our data contains some NAs. There are multiple reasons for it:

* In the month of March 2020, Natural_Gas values have been reported on Sunday
* The first column "Natural_Gas" is not an american index. Therefore, its values have been reported on days, when there were holidays in the US, resulting in approximately 25 NAs in years 2015 onward.
* NG has not been reported for two consecutive weeks in September 2005. Since the futures are priced similarly for this period, we will substitute the missing data with the prices of futures


```{r nat_gas_fut}
nat_gas_fut<- read_excel("data/shiny/NG_PRI_FUT_S1_D.xls", sheet = "Data 2", skip = 2) %>%
  rename("Natural_Gas_Fut" = 2) %>% dplyr::select(1,2)

nat_gas_df<-nat_gas_spot%>% full_join(nat_gas_fut) %>% filter(Date >= "2005-09-16",Date<="2005-10-17") %>% arrange(Date)

nat_gas_df %>%
  kbl()%>%
  kable_classic_2(full_width = F)

```


```{r NA before}
NA_dates <- df %>%
  filter_at(vars(-Date,-Day,-Holiday), all_vars(is.na(.))) %>%
  pull(Date)
df <- df %>% dplyr::filter(!Date %in% NA_dates) %>% dplyr::filter(Day!="Sunday")
df_NA<-df %>% filter_at(vars(-Date,-Day,-Holiday), any_vars(is.na(.)))
df_NA %>%
  kbl()%>%
  kable_classic_2(full_width = F)
```


### Missing after all systematic NA sources have been dealt with

```{r NA after}
##replace missing Nat_Gas spot prices with futures
na_2005<-nat_gas_df[!complete.cases(nat_gas_df),] %>% mutate(Date=as.Date(Date)) %>% dplyr::select(-"Natural_Gas")
df<-df%>%left_join(na_2005) %>% mutate(Natural_Gas = coalesce(Natural_Gas,Natural_Gas_Fut)) %>%dplyr::select(-"Natural_Gas_Fut")

#Remove data where there was a holiday and the metrics were not reported
df<-df %>% dplyr::filter(!(!is.na(Holiday) &
                             (is.na(Crude_Oil_WTI) | is.na(Natural_Gas) | 
                                is.na(NY_Gasoline) | is.na(Heating_Oil) | is.na(Diesel))
                           ))
df_NA<-df %>% filter_at(vars(-Date,-Day,-Holiday), any_vars(is.na(.)))
df_NA %>%
  kbl()%>%
  kable_classic_2(full_width = F)
# rest is substituted with the previous days price
for(i in 4:length(df)){
  df[,i]<-imputeTS::na_ma(df[,i], k = 1, weighting = "simple")
}
```

### Prices
```{r prices_stats,echo=F}
long_df <- reshape2::melt(df, id.vars = c("Date","Day","Holiday"))
  selectInput("period", "Choose a period:",
      list(`Period` = list("All","Pre-GFC", "GFC", "EU debt crisis", "Post-EU debt crisis","Covid"))
    )



renderPlot({
dt_from<-case_when(input$period == "Pre-GFC" ~ "1997-01-07",
          input$period == "GFC"~"2008-09-15",
          input$period == "EU debt crisis"~"2010-05-03",
          input$period == "Post-EU debt crisis"~"2012-07-27",
          input$period == "Covid"~"2020-02-02",
          input$period == "All"~"1997-01-07")
dt_to<-case_when(input$period == "Pre-GFC" ~ "12008-09-14",
          input$period == "GFC"~"2010-04-30",
          input$period == "EU debt crisis"~"2012-07-26",
          input$period == "Post-EU debt crisis"~"2020-02-01",
          input$period == "Covid"~"2022-01-01",
          input$period == "All"~"2022-01-01")         
          

long_df_aux<-long_df[long_df$Date>=dt_from,]
long_df_aux<-long_df_aux[long_df_aux$Date<=dt_to,]

ggplot(long_df_aux, aes(x = Date, y = value)) +
  geom_line() +
  facet_wrap(~variable, scales = "free") +
  ggtitle("Prices") +
  geom_vline(xintercept = as.POSIXct("2008-9-15"), color = "Red")
})

renderPlot({
dt_from<-case_when(input$period == "Pre-GFC" ~ "1997-01-07",
          input$period == "GFC"~"2008-09-15",
          input$period == "EU debt crisis"~"2010-05-03",
          input$period == "Post-EU debt crisis"~"2012-07-27",
          input$period == "Covid"~"2020-02-02",
          input$period == "All"~"1997-01-07")
dt_to<-case_when(input$period == "Pre-GFC" ~ "12008-09-14",
          input$period == "GFC"~"2010-04-30",
          input$period == "EU debt crisis"~"2012-07-26",
          input$period == "Post-EU debt crisis"~"2020-02-01",
          input$period == "Covid"~"2022-01-01",
          input$period == "All"~"2022-01-01")  
long_df_aux<-long_df[long_df$Date>dt_from,]
long_df_aux<-long_df_aux[long_df_aux$Date<dt_to,]

ggplot(long_df_aux, aes(factor(variable), value)) + 
  geom_boxplot() + 
  facet_wrap(~variable, scale="free")
})

```


We see that this **crude oil WTI metric** had negative prices at one point. This would not let us do log-returns, so we substitute with low value for now. Should be treated more rigorously later on.

```{r crude_oil_sub}
for (i in 1:nrow(df)){
  val<-df[i,"Crude_Oil_WTI"]
  if(val<0){
    df[i,"Crude_Oil_WTI"] <-(df[i-1,"Crude_Oil_WTI"]+df[i+1,"Crude_Oil_WTI"])/2
  }
}
df[df$Date=="2020-04-20","Crude_Oil_WTI"]
```

## Log returns

```{r log_ret}
log_ret_df <- tibble(df[2:nrow(df), "Date"])
for (i in 4:(ncol(df))) {
  var_name <- paste(colnames(df)[i], "log_ret", sep = "_")
  vals <- log(df[, i]) %>% pull()
  lag_vals <- base::diff(vals, lag = 1)
  log_ret_df[var_name] <- lag_vals
}
long_log_ret <- melt(log_ret_df, id.vars = "Date")
dates<-log_ret_df %>% dplyr::select(1)%>%pull()
char_dates<-as.character(dates)
```

### Structural changes estimation

```{r struct_change, eval = F, include = F}
#save BP object
for(i in 2:length(log_ret_df)){
  col<-colnames(log_ret_df)[i]
  print(col)
  val<-log_ret_df %>% dplyr::select(i)%>%pull() 
  ##Chow Test: H0: no structural break in the data
  chow<-sctest(I(val^2)~1,type="Chow")
  ## Bai Perron
  bp <- breakpoints(I(val^2) ~ 1,h=600) 
  bp_name<-paste("data/shiny/bp","_", col,".rds",sep="")
  chow_name<-paste("data/shiny/chow","_", col,".rds",sep="")
  print(bp_name)
  saveRDS(bp,file=bp_name)
  saveRDS(chow,file=chow_name)
}

input<-colnames(log_ret_df)[-c(1)]
#save Plots and Breakpoints
for (i in input){
bp_name<-paste("data/shiny/bp","_", i,".rds",sep="")
print(bp_name)
bp<-readRDS(bp_name)

bp_plot<-plot(bp)
sum_bp<-summary(bp)
sum_bp_df<-sum_bp$breakpoints%>%as.data.frame()
bp_break_dates<-sapply(sum_bp_df,function(x) char_dates[x]) %>% as.data.frame()

bp_name_plot<-paste("data/shiny/plots/bp_plot","_", i,".rds",sep="")
bp_name_dates<-paste("data/shiny/break_dates/bp_break_dates","_", i,".rds",sep="")

saveRDS(bp_plot,file=bp_name_plot)
saveRDS(bp_break_dates,file=bp_name_dates)
}
```

```{r breakpoints, echo = F, include=F}
dates<-log_ret_df %>% dplyr::select(1)%>%pull()
char_dates<-as.character(dates)
selectInput("struct_change", "Choose a series:",
      list(`Log Returns Period` = colnames(log_ret_df[-1]))
    )
renderPrint({
   chow_name<-paste("data/shiny/chow","_", input$struct_change,".rds",sep="") 
   chow<-readRDS(chow_name)
    print("Chow test (H0: there are no structural brakes)")
    print(chow)
})
renderTable({
   bp_name<-paste("data/shiny/break_dates/bp_break_dates_", input$struct_change,".rds",sep="")
   bp_df<-readRDS(bp_name)
   rownames(bp_df)<-paste(rep(1:nrow(bp_df)),"Breakpoints modeled")
   colnames(bp_df)<-paste("Breakpoint",rep(1:nrow(bp_df)))
   bp_df
},rownames = TRUE)
renderPlot({
   bp_name<-paste("data/shiny/plots/bp_plot_", input$struct_change,".rds",sep="")
   bp<-readRDS(bp_name)
   plot(bp)
})
```


```{r corplot_logret,echo=F,message=T,warning=T}

selectInput("period_corrplot", "Choose a period:",
      list(`Log Returns Period` = list("All","Pre-GFC", "GFC", "EU debt crisis", "Post-EU debt crisis","Covid"))
    )

renderPlot({
dt_from<-case_when(input$period_corrplot == "Pre-GFC" ~ "1997-01-07",
          input$period_corrplot == "GFC"~"2008-09-15",
          input$period_corrplot == "EU debt crisis"~"2010-05-03",
          input$period_corrplot == "Post-EU debt crisis"~"2012-07-27",
          input$period_corrplot == "Covid"~"2020-02-02",
          input$period_corrplot == "All"~"1997-01-07")
dt_to<-case_when(input$period_corrplot == "Pre-GFC" ~ "12008-09-14",
          input$period_corrplot == "GFC"~"2010-04-30",
          input$period_corrplot == "EU debt crisis"~"2012-07-26",
          input$period_corrplot == "Post-EU debt crisis"~"2020-02-01",
          input$period_corrplot == "Covid"~"2022-01-01",
          input$period_corrplot == "All"~"2022-01-01")


log_ret_df <- tibble(df[2:nrow(df), "Date"])

for (i in 4:(ncol(df))) {
  var_name <- paste(colnames(df)[i], "log_ret", sep = "_")
  vals <- log(df[, i]) %>% pull()
  lag_vals <- base::diff(vals, lag = 1)
  log_ret_df[var_name] <- lag_vals
}
log_ret_aux2<-log_ret_df[(log_ret_df$Date>=dt_from & log_ret_df$Date<=dt_to),]
corr <- round(cor(log_ret_aux2[-1]),12)
#log_ret_aux2["Date"]<-as.Date(log_ret_aux2["Date"]*24*60*60, origin = "1970-01-01", tz="UTC")
ggcorrplot(corr, hc.order = TRUE, type = "lower",lab = TRUE)
})

renderPlot({
dt_from<-case_when(input$period_corrplot == "Pre-GFC" ~ "1997-01-07",
          input$period_corrplot == "GFC"~"2008-09-15",
          input$period_corrplot == "EU debt crisis"~"2010-05-03",
          input$period_corrplot == "Post-EU debt crisis"~"2012-07-27",
          input$period_corrplot == "Covid"~"2020-02-02",
          input$period_corrplot == "All"~"1997-01-07")
dt_to<-case_when(input$period_corrplot == "Pre-GFC" ~ "12008-09-14",
          input$period_corrplot == "GFC"~"2010-04-30",
          input$period_corrplot == "EU debt crisis"~"2012-07-26",
          input$period_corrplot == "Post-EU debt crisis"~"2020-02-01",
          input$period_corrplot == "Covid"~"2022-01-01",
          input$period_corrplot == "All"~"2022-01-01")

log_ret_aux<-long_log_ret[(long_log_ret$Date>=dt_from &long_log_ret$Date<=dt_to),]

ggplot(log_ret_aux, aes(x = Date, y = value)) +
  geom_line() +
  facet_wrap(~variable, scales = "free") +
  ggtitle("Log Returns - May be stationary")

})
```


### Summary and Statistical Tests
```{r test_prep, echo = F}
selectInput("period_table", "Choose a period:",
      list(`Log Returns Period` = list("All","Pre-GFC", "GFC", "EU debt crisis", "Post-EU debt crisis","Covid"))
    )
renderTable({
dt_from<-case_when(input$period_table == "Pre-GFC" ~ "1997-01-07",
          input$period_table == "GFC"~"2008-09-15",
          input$period_table == "EU debt crisis"~"2010-05-03",
          input$period_table == "Post-EU debt crisis"~"2012-07-27",
          input$period_table == "Covid"~"2020-02-02",
          input$period_table == "All"~"1997-01-07")
dt_to<-case_when(input$period_table == "Pre-GFC" ~ "12008-09-14",
          input$period_table == "GFC"~"2010-04-30",
          input$period_table == "EU debt crisis"~"2012-07-26",
          input$period_table == "Post-EU debt crisis"~"2020-02-01",
          input$period_table == "Covid"~"2022-01-01",
          input$period_table == "All"~"2022-01-01")

log_ret_df <- tibble(df[2:nrow(df), "Date"])

for (i in 4:(ncol(df))) {
  var_name <- paste(colnames(df)[i], "log_ret", sep = "_")
  vals <- log(df[, i]) %>% pull()
  lag_vals <- base::diff(vals, lag = 1)
  log_ret_df[var_name] <- lag_vals
}

long_log_ret<-long_log_ret[(long_log_ret$Date>=dt_from &long_log_ret$Date<=dt_to),]
log_ret_df<-log_ret_df[(log_ret_df$Date>=dt_from & log_ret_df$Date<=dt_to),]  
  
summary_df<-long_log_ret %>% group_by(as.factor(variable)) %>%
  get_summary_stats(type = "common") %>%dplyr::select(-variable,n) %>% 
  rename("variable" = 1)%>%
  data.table::transpose( keep.names = "col",make.names = "variable")
rownames(summary_df)<-summary_df[,1]
summary_df<-summary_df[-1]

summary_df[c("skewness", "kurtosis"),] <- rbind(c(round(sapply(log_ret_df[c(2:6)],skewness),3),
                                                  round(sapply(log_ret_df[c(2:6)],kurtosis),3)))
colnames(summary_df) <- stylized_names

ar_1_list <- list()
q_10_list<- list()
q2_10_list<- list()
ma_1_list <- list()
arch_5_list<-list()
shapiro_norm_list<-list()
adf_list<-list()
jarque_bera_list<-list()

for(i in 2:length(log_ret_df)){
  val<-log_ret_df[,i] %>% pull()
  lag_val<-lag(val,1)
  res<-lm(val~lag_val)$residuals
  shapiro_norm_list[[i-1]]<-shapiro.test(sample(val,size=min(5000,length(val)),replace = F))
  adf_list[[i-1]] <- adf.test(val)
  ma_1_list[[i-1]] <- arima(val, order = c(0, 0, 1)) 
  ar_1_list[[i-1]] <- arima( res, order = c(1, 0, 0))
  q_10_list[[i-1]]<-Box.test(res, lag = 10, type =  "Ljung-Box")
  q2_10_list[[i-1]]<-Box.test(res^2, lag = 10, type =  "Ljung-Box")
  arch_5_list[[i-1]]<- quiet(garch(res,c(0,5)))
  jarque_bera_list[[i-1]]<-jarque.bera.test(val)
}

res_matrix<-data.frame(matrix(ncol=length(stylized_names),nrow=14))
x <- c("name", "age", "gender")
colnames(res_matrix) <- stylized_names
rownames(res_matrix)<-c("Shapiro Normality","Shapiro Normality PVal","ADF","ADF Pval","Q(10)","Q(10) Pval","Q2(10)","Q2(10) Pval","ARCH(5)","ARCH(5) Pval","AR(1)","AR(1) Pval","Jarque-Berra","Jarque Berra Pval")

for (i in 1:length(stylized_names)){
  res_matrix[1,i]<-round(shapiro_norm_list[[i]]$statistic,2)
  res_matrix[2,i]<-shapiro_norm_list[[i]]$p.value
  res_matrix[3,i]<-round(adf_list[[i]]$statistic,2)
  res_matrix[4,i]<-adf_list[[i]]$p.value
  res_matrix[5,i]<-round(q_10_list[[i]]$statistic,2)
  res_matrix[6,i]<-q_10_list[[i]]$p.value
  res_matrix[7,i]<-round(q2_10_list[[i]]$statistic,2)
  res_matrix[8,i]<-q2_10_list[[i]]$p.value
  arch_res<-coeftest(arch_5_list[[i]])
  res_matrix[9,i]<-round(arch_res[6,1],3)
  res_matrix[10,i]<-arch_res[6,4]
  ar_res<-coeftest(ar_1_list[[i]])
  res_matrix[11,i]<-round(ar_res[1,1],3)
  res_matrix[12,i]<-ar_res[1,4]
  res_matrix[13,i]<-round(jarque_bera_list[[i]]$statistic,3)
  res_matrix[14,i]<-jarque_bera_list[[i]]$p.value
}

for (i in 1:length(res_matrix)){
  row <- as.character(res_matrix[,i])
  for (j in seq(from = 1, to = length(row)-1,by = 2)){
    coef<-round(as.numeric(row[j]),4)
    pval<-as.numeric(row[j+1])
    row[j]<-ifelse(pval<=0.001,paste(coef,"***",sep=""),
                   ifelse(pval<=0.01,paste(coef,"**",sep=""),
                          ifelse(pval<=0.05,paste(coef,"*",sep=""),as.character(coef))))
    row[j+1]<-as.character(round(pval,5))
  }
  res_matrix[,i]<-row
}

final_df<-summary_df %>% rbind(res_matrix)
final_df
},
rownames = TRUE, width="100%",spacing="xs")
```

## Spillovers

All functions are documented in the frequencyConnectedness package on [Cran](https://cran.r-project.org/web/packages/frequencyConnectedness/frequencyConnectedness.pdf). Here I use only the spilloverDY09 index (according to Diebold Yilmaz (2009)).

```{r spillovers spec}
sp_list<-lsf.str("package:frequencyConnectedness")
sp_list<-sp_list[str_detect(sp_list,"spill")]
print(sp_list)
```

### Check appropriate VAR lag by adjusted R squared?

#### Max Lag set to 15
```{r VAR}
opt_lag<-VARselect(log_ret_df[-c(1)]^2,type="const",lag.max=15)
df_opt<-data.frame(t(opt_lag$criteria))
rownames(df_opt)<-paste("Lag",rep(1:nrow(df_opt)))
df_opt%>%
  kbl()%>%
  kable_classic_2(full_width = F)
opt_lag$selection
```
#### Max Lag set to 4
```{r maxlag 4}
opt_lag<-VARselect(log_ret_df[-1],type="const",lag.max=4)
df_opt<-data.frame(t(opt_lag$criteria))
rownames(df_opt)<-paste("Lag",rep(1:nrow(df_opt)))
df_opt%>%
  kbl()%>%
  kable_classic_2(full_width = F)
opt_lag$selection
```

#### Testing of AR in residuals for vars::VAR(2) and vars::VAR(4)
```{r AR for VAR, echo=F}
var_2 <- vars::VAR(log_ret_df[-1], p = 2, type = "const")
var_4<- vars::VAR(log_ret_df[-1], p = 4, type = "const")

ar_lag2_list<-list()
ar_lag4_list<-list()
for(i in 1:length(var_2$varresult)){
  res2<-var_2$varresult[i][[1]]$residuals
  res4<-var_4$varresult[i][[1]]$residuals
  ar_lag2_list[[i]] <- arima( res2, order = c(1, 0, 0))
  ar_lag4_list[[i]] <- arima( res4, order = c(1, 0, 0))
}
```


#### AR of residuals with lag 2
```{r stargazer2,results='asis'}
stargazer(ar_lag2_list,type="html",align = T)
```

#### AR of residuals with lag 4
```{r stargazer4,results='asis'}
stargazer(ar_lag4_list,type="html",align = T)
```


```{r sp_tables, eval = F, include =F}
overall(sp) %>% kbl()
to(sp) %>% kbl()
from(sp) %>% kbl()
net(sp) %>% kbl()
pairwise(sp) %>% kbl()
```

#### Forecast error vector decmposition in recursive identification scheme

```{r}
est<-vars::VAR(log_ret_df[-1], p = 2, type = "const")
forecast<-fevd(est)
#a matrix that corresponds to contribution of ith variable to jth variance of forecast
forecast %>%
  kbl()%>%
  kable_classic_2(full_width = F)
```
## Switching to Rolling Spillover

#### Investigating the huge spillovers
```{r rolling_sp}
# Get the rolling window estimates
params_est = list(p = 2, type = "const")
ahead=100
window_size=100
dates<-log_ret_df[1:nrow(log_ret_df),1] %>% pull()
#sp <- spilloverRollingDY12(log_ret_df[-1], n.ahead =ahead, no.corr = F, "VAR", params_est = params_est, window = window_size)

sp<-readRDS("data/shiny/sp.rds")
for (i in 1:length(sp[[1]])){
  sp[[1]][[i]]$date<-as.POSIXct(dates[i])
}
ov_sp<-overall(sp)[[1]] %>% as.data.frame()
ov_sp <- cbind(1:nrow(ov_sp),rownames(ov_sp), ov_sp)
rownames(ov_sp) <- 1:nrow(ov_sp)
colnames(ov_sp)<-c("Index","Date","val")
ov_sp %>% arrange(desc(val)) %>% head(n=10) %>%
    kbl()%>%
    kable_classic_2(full_width = F)
```

Observe the VAR matrix for a window ending with one of the spikes
```{r sp_100}
## Calculate non-rolling SP only on this window
test<-log_ret_df[663:763,-1]
est100 <- vars::VAR(test, p = 2, type = "const")
sp_100<-spilloverDY12(est100, n.ahead = 100, no.corr = F)
sp_100
z<-summary(est100)
#Observe the heating oil specifically
z$varresult[[4]]
```

### Various n.ahead (a) and windows (w)
Summary: 

only the window parameter influences values

bigger window produces smaller spikes
```{r echo = F}
sp_plots<-list.files("./data/shiny/sp_data/plots")
par(mfrow=c(3,3))
for (i in sp_plots){
  sp_plot<-readRDS(paste0("data/shiny/sp_data/plots/",i))
  plot(sp_plot,main=i)
}
```


```{r sp_100_200}
sp_100_200<-readRDS("data/shiny/sp_data/spa100w200")
ov_sp<-overall(sp_100_200)[[1]] %>% as.data.frame()
ov_sp <- cbind(1:nrow(ov_sp),rownames(ov_sp), ov_sp)
rownames(ov_sp) <- 1:nrow(ov_sp)
colnames(ov_sp)<-c("Index","Date","val")
ov_sp %>% arrange(desc(val)) %>% head(n=10) %>%
    kbl()%>%
    kable_classic_2(full_width = F)
```

```{r plot_rolling}
# plotOverall(sp)
# plotTo(sp)
# plotFrom(sp)
# plotNet(sp)
# plotPairwise(sp)
```



```{r include = F, eval = F}
library(parallel)
cl <- makeCluster(8)
sp <- spilloverRollingDY12(log_ret_df[-1], n.ahead = 100, no.corr = F, func_est = "VAR", 
                           params_est = list(p = 2, type = "const"), 
                           window = 100,cluster  = cl)
plotOverall(sp)
nm<-paste0("sp","a",200,"w",space+1)
fullnm<-paste0("data/shiny/sp_data/",nm)
saveRDS(sp,fullnm)
stopCluster(cl)

sp_ls<-list.files("./data/shiny/sp_data")
sp_ls<-sp_ls[-1]
for (i in sp_ls){
  print(i)
  sp<-readRDS(paste0("data/shiny/sp_data/",i))
  space<-length(dates)-length(sp[[1]])+1
  print(space)
  dates_temp<-dates[space:length(dates)]
  for (j in 1:length(sp[[1]])){
    sp[[1]][[j]]$date<-as.POSIXct(dates_temp[j])
  }
  ov_plot<-plotOverall(sp)
  ov_plot_nm<-paste0("data/shiny/sp_data/plots/",i)
  saveRDS(ov_plot,ov_plot_nm)
}
```

